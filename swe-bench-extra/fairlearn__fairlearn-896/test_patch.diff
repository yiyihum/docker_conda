diff --git a/test/unit/metrics/test_metricframe_aggregates.py b/test/unit/metrics/test_metricframe_aggregates.py
index 249fa94..da3df53 100644
--- a/test/unit/metrics/test_metricframe_aggregates.py
+++ b/test/unit/metrics/test_metricframe_aggregates.py
@@ -1,5 +1,6 @@
 # Copyright (c) Microsoft Corporation and Fairlearn contributors.
 # Licensed under the MIT License.
+import functools
 
 import numpy as np
 import pandas as pd
@@ -9,7 +10,10 @@ import sklearn.metrics as skm
 import fairlearn.metrics as metrics
 
 from .data_for_test import y_t, y_p, g_1, g_2, g_3, g_4
-
+from fairlearn.metrics._metric_frame import (
+    _INVALID_ERRORS_VALUE_ERROR_MESSAGE,
+    _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE
+)
 
 metric = [skm.recall_score,
           skm.precision_score,
@@ -1040,3 +1044,670 @@ def test_2m_1sf_2cf():
         assert ratios_overall[mfn][('m', 'aa')] == min(ratio_overall_m_a)
         assert ratios_overall[mfn][('m', 'ba')] == pytest.approx(min(ratio_overall_m_b),
                                                                  rel=1e-10, abs=1e-16)
+
+
+class Test2m1sf1cfErrorHandlingCM:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    def _prepare(self):
+        fns = {'recall': skm.recall_score, 'confusion_matrix': skm.confusion_matrix}
+        self.target = metrics.MetricFrame(metrics=fns, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2,
+                                          control_features=g_3)
+
+        self.expected = metrics.MetricFrame(metrics={'recall': skm.recall_score},
+                                            y_true=y_t,
+                                            y_pred=y_p,
+                                            sensitive_features=g_2,
+                                            control_features=g_3)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        expected_mins = self.expected.group_min()
+        expected_mins['confusion_matrix'] = np.nan
+        assert target_mins.equals(expected_mins)
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        expected_maxs = self.expected.group_max()
+        expected_maxs['confusion_matrix'] = np.nan
+        assert target_maxs.equals(expected_maxs)
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+
+class Test1m1sf1cfErrorHandlingCM:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    def _prepare(self):
+        fns = {'confusion_matrix': skm.confusion_matrix}
+        self.target = metrics.MetricFrame(metrics=fns, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2,
+                                          control_features=g_3)
+
+        self.expected = metrics.MetricFrame(metrics={}, y_true=y_t, y_pred=y_p,
+                                            sensitive_features=g_2,
+                                            control_features=g_3)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        expected_mins = self.expected.group_min()
+        expected_mins['confusion_matrix'] = np.nan
+        assert target_mins.equals(expected_mins)
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        expected_maxs = self.expected.group_max()
+        expected_maxs['confusion_matrix'] = np.nan
+        assert target_maxs.equals(expected_maxs)
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+
+class Test2m1sf0cfErrorHandlingCM:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    def _prepare(self):
+        fns = {'recall': skm.recall_score, 'confusion_matrix': skm.confusion_matrix}
+        self.target = metrics.MetricFrame(metrics=fns, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2)
+
+        self.expected = metrics.MetricFrame(metrics={'recall': skm.recall_score},
+                                            y_true=y_t,
+                                            y_pred=y_p,
+                                            sensitive_features=g_2)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        expected_mins = self.expected.group_min()
+        expected_mins['confusion_matrix'] = np.nan
+        assert target_mins.equals(expected_mins)
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        expected_maxs = self.expected.group_max()
+        expected_maxs['confusion_matrix'] = np.nan
+        assert target_maxs.equals(expected_maxs)
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        expected_differences = self.expected.difference()
+        expected_differences['confusion_matrix'] = np.nan
+        assert target_differences.equals(expected_differences)
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        expected_ratio = self.expected.ratio()
+        expected_ratio['confusion_matrix'] = np.nan
+        assert target_ratio.equals(expected_ratio)
+
+
+class Test1m1sf0cfErrorHandlingCM:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    def _prepare(self):
+        fns = {'confusion_matrix': skm.confusion_matrix}
+        self.target = metrics.MetricFrame(metrics=fns, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        assert target_mins.isna().all()
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        assert target_maxs.isna().all()
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        assert target_differences.isna().all()
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        assert target_differences.isna().all()
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        assert target_ratio.isna().all()
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        assert target_ratio.isna().all()
+
+
+class Test2m1sf0cfErrorHandlingCM2:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    # Tests for two non-scalar columns in MetricFrame.
+    def _prepare(self):
+        fns = {'confusion_matrix1': skm.confusion_matrix,
+               'confusion_matrix2': functools.partial(skm.confusion_matrix, normalize='all')}
+        self.target = metrics.MetricFrame(metrics=fns, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        assert target_mins.isna().all()
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        assert target_maxs.isna().all()
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        assert target_differences.isna().all()
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        assert target_differences.isna().all()
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        assert target_ratio.isna().all()
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        assert target_ratio.isna().all()
+
+
+class Test1m1sf0cfErrorHandlingSeries:
+    # Metricframe containing a confusion matrix raises ValueErrors, since cells are non-scalar
+    # Tests for two non-scalar columns in MetricFrame.
+    def _prepare(self):
+        self.target = metrics.MetricFrame(metrics=skm.confusion_matrix, y_true=y_t, y_pred=y_p,
+                                          sensitive_features=g_2)
+
+    def test_min_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_coerce(self):
+        self._prepare()
+        target_mins = self.target.group_min(errors='coerce')
+        assert np.isnan(target_mins)
+
+    def test_min_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_min_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_min(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_coerce(self):
+        self._prepare()
+        target_maxs = self.target.group_max(errors='coerce')
+        assert np.isnan(target_maxs)
+
+    def test_max_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_max_default(self):
+        # default is 'raise'
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.group_max(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_coerce(self):
+        self._prepare()
+        target_differences = self.target.difference(errors='coerce')
+        assert np.isnan(target_differences)
+
+    def test_difference_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.difference(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_difference_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_differences = self.target.difference()
+        assert np.isnan(target_differences)
+
+    def test_ratio_raise(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='raise')
+        assert _MF_CONTAINS_NON_SCALAR_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_coerce(self):
+        self._prepare()
+        target_ratio = self.target.ratio(errors='coerce')
+        assert np.isnan(target_ratio)
+
+    def test_ratio_wrong_input(self):
+        self._prepare()
+        with pytest.raises(ValueError) as exc:
+            self.target.ratio(errors='WRONG')
+        assert _INVALID_ERRORS_VALUE_ERROR_MESSAGE == exc.value.args[0]
+
+    def test_ratio_default(self):
+        # default is 'coerce'
+        self._prepare()
+        target_ratio = self.target.ratio()
+        assert np.isnan(target_ratio)
