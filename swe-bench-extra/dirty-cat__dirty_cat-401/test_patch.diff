diff --git a/dirty_cat/tests/test_docstrings.py b/dirty_cat/tests/test_docstrings.py
index 7177f69..c8772bb 100644
--- a/dirty_cat/tests/test_docstrings.py
+++ b/dirty_cat/tests/test_docstrings.py
@@ -35,7 +35,6 @@ DOCSTRING_TEMP_IGNORE_SET = {
     "dirty_cat._similarity_encoder.SimilarityEncoder.fit",
     "dirty_cat._similarity_encoder.SimilarityEncoder.transform",
     "dirty_cat._similarity_encoder.SimilarityEncoder.fit_transform",
-    "dirty_cat._super_vectorizer.SuperVectorizer",
     "dirty_cat._super_vectorizer.SuperVectorizer.fit_transform",
     "dirty_cat._super_vectorizer.SuperVectorizer.transform",
     "dirty_cat._super_vectorizer.SuperVectorizer._auto_cast",
@@ -148,17 +147,18 @@ def filter_errors(errors, method, Estimator=None):
         #  - GL02: If there's a blank line, it should be before the
         #    first line of the Returns section, not after (it allows to have
         #    short docstrings for properties).
+        #  - SA01: See Also section not found
+        #  - EX01: No examples section found; FIXME: remove when #373 resolved
 
-        if code in ["RT02", "GL01", "GL02"]:
+        if code in ["RT02", "GL01", "GL02", "SA01", "EX01"]:
             continue
 
         # Following codes are only taken into account for the
         # top level class docstrings:
         #  - ES01: No extended summary found
-        #  - SA01: See Also section not found
         #  - EX01: No examples section found
 
-        if method is not None and code in ["EX01", "SA01", "ES01"]:
+        if method is not None and code in ["EX01", "ES01"]:
             continue
 
         yield code, message
diff --git a/dirty_cat/tests/test_gap_encoder.py b/dirty_cat/tests/test_gap_encoder.py
index 3c4ecc0..f891508 100644
--- a/dirty_cat/tests/test_gap_encoder.py
+++ b/dirty_cat/tests/test_gap_encoder.py
@@ -2,10 +2,10 @@ import numpy as np
 import pandas as pd
 import pytest
 from sklearn import __version__ as sklearn_version
-from sklearn.datasets import fetch_20newsgroups
 
 from dirty_cat import GapEncoder
 from dirty_cat._utils import Version
+from dirty_cat.tests.utils import generate_data
 
 
 def test_analyzer():
@@ -15,8 +15,7 @@ def test_analyzer():
     """
     add_words = False
     n_samples = 70
-    X_txt = fetch_20newsgroups(subset="train")["data"][:n_samples]
-    X = np.array([X_txt, X_txt]).T
+    X = generate_data(n_samples)
     n_components = 10
     # Test first analyzer output:
     encoder = GapEncoder(
@@ -56,8 +55,7 @@ def test_analyzer():
 def test_gap_encoder(
     hashing: bool, init: str, analyzer: str, add_words: bool, n_samples: int = 70
 ) -> None:
-    X_txt = fetch_20newsgroups(subset="train")["data"][:n_samples]
-    X = np.array([X_txt, X_txt]).T
+    X = generate_data(n_samples)
     n_components = 10
     # Test output shape
     encoder = GapEncoder(
@@ -117,8 +115,7 @@ def test_input_type() -> None:
 
 
 def test_partial_fit(n_samples=70) -> None:
-    X_txt = fetch_20newsgroups(subset="train")["data"][:n_samples]
-    X = np.array([X_txt, X_txt]).T
+    X = generate_data(n_samples)
     # Gap encoder with fit on one batch
     enc = GapEncoder(random_state=42, batch_size=n_samples, max_iter=1)
     X_enc = enc.fit_transform(X)
@@ -131,8 +128,7 @@ def test_partial_fit(n_samples=70) -> None:
 
 
 def test_get_feature_names_out(n_samples=70) -> None:
-    X_txt = fetch_20newsgroups(subset="train")["data"][:n_samples]
-    X = np.array([X_txt, X_txt]).T
+    X = generate_data(n_samples)
     enc = GapEncoder(random_state=42)
     enc.fit(X)
     # Expect a warning if sklearn >= 1.0
@@ -164,8 +160,7 @@ def test_overflow_error() -> None:
 
 
 def test_score(n_samples: int = 70) -> None:
-    X_txt = fetch_20newsgroups(subset="train")["data"][:n_samples]
-    X1 = np.array(X_txt)[:, None]
+    X1 = generate_data(n_samples)
     X2 = np.hstack([X1, X1])
     enc = GapEncoder(random_state=42)
     enc.fit(X1)
diff --git a/dirty_cat/tests/utils.py b/dirty_cat/tests/utils.py
index b710d5b..15da3e1 100644
--- a/dirty_cat/tests/utils.py
+++ b/dirty_cat/tests/utils.py
@@ -5,7 +5,6 @@ import numpy as np
 
 def generate_data(n_samples, as_list=False):
     MAX_LIMIT = 255  # extended ASCII Character set
-    i = 0
     str_list = []
     for i in range(n_samples):
         random_string = "category "
@@ -14,7 +13,6 @@ def generate_data(n_samples, as_list=False):
             random_string += chr(random_integer)
             if random_integer < 50:
                 random_string += "  "
-        i += 1
         str_list += [random_string]
     if as_list is True:
         X = str_list
