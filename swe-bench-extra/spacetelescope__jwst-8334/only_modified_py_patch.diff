diff --git a/jwst/charge_migration/charge_migration.py b/jwst/charge_migration/charge_migration.py
index 30e1b9bc1..ccfcc3836 100644
--- a/jwst/charge_migration/charge_migration.py
+++ b/jwst/charge_migration/charge_migration.py
@@ -5,6 +5,7 @@ import numpy as np
 
 from stdatamodels.jwst.datamodels import dqflags
 
+
 log = logging.getLogger(__name__)
 log.setLevel(logging.DEBUG)
 
@@ -72,72 +73,29 @@ def flag_pixels(data, gdq, signal_threshold):
         updated group dq array
     """
     n_ints, n_grps, n_rows, n_cols = gdq.shape
-
-    new_gdq = gdq.copy()   # Updated gdq
-
-    # Flag all exceedances with CHARGELOSS and NO_NOT_USE
-    chargeloss_pix = (data > signal_threshold) & (gdq != DNU)
-    new_gdq[chargeloss_pix] = np.bitwise_or(new_gdq[chargeloss_pix], CHLO | DNU)
-
-    # Reset groups previously flagged as DNU
-    gdq_orig = gdq.copy()  # For resetting to previously flagged DNU
-    wh_gdq_DNU = np.bitwise_and(gdq_orig, DNU)
-
-    # Get indices for exceedances
-    arg_where = np.argwhere(new_gdq == CHLO_DNU)
-
-    a_int = arg_where[:, 0]  # array of integrations
-    a_grp = arg_where[:, 1]  # array of groups
-    a_row = arg_where[:, 2]  # array of rows
-    a_col = arg_where[:, 3]  # array of columns
-
-    # Process the 4 nearest neighbors of each exceedance
-    # Pixel to the east
-    xx_max_p1 = a_col[a_col < (n_cols-1)] + 1
-    i_int = a_int[a_col < (n_cols-1)]
-    i_grp = a_grp[a_col < (n_cols-1)]
-    i_row = a_row[a_col < (n_cols-1)]
-
-    if len(xx_max_p1) > 0:
-        new_gdq[i_int, i_grp, i_row, xx_max_p1] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, i_row, xx_max_p1], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the west
-    xx_m1 = a_col[a_col > 0] - 1
-    i_int = a_int[a_col > 0]
-    i_grp = a_grp[a_col > 0]
-    i_row = a_row[a_col > 0]
-
-    if len(xx_m1) > 0:
-        new_gdq[i_int, i_grp, i_row, xx_m1] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, i_row, xx_m1], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the north
-    yy_m1 = a_row[a_row > 0] - 1
-    i_int = a_int[a_row > 0]
-    i_grp = a_grp[a_row > 0]
-    i_col = a_col[a_row > 0]
-
-    if len(yy_m1) > 0:
-        new_gdq[i_int, i_grp, yy_m1, i_col] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, yy_m1, i_col], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the south
-    yy_max_p1 = a_row[a_row < (n_rows-1)] + 1
-    i_int = a_int[a_row < (n_rows-1)]
-    i_grp = a_grp[a_row < (n_rows-1)]
-    i_col = a_col[a_row < (n_rows-1)]
-
-    if len(yy_max_p1) > 0:
-        new_gdq[i_int, i_grp, yy_max_p1, i_col] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, yy_max_p1, i_col], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
+    chargeloss_pix = np.where((data > signal_threshold) & (gdq != DNU))
+
+    new_gdq = gdq.copy()
+    
+    for k in range(len(chargeloss_pix[0])): 
+        integ, group = chargeloss_pix[0][k], chargeloss_pix[1][k]
+        row, col = chargeloss_pix[2][k], chargeloss_pix[3][k]
+        new_gdq[integ, group:, row, col] |= CHLO_DNU
+
+        # North
+        if row > 0:
+            new_gdq[integ, group:, row-1, col] |= CHLO_DNU
+
+        # South
+        if row < (n_rows-1):
+            new_gdq[integ, group:, row+1, col] |= CHLO_DNU
+
+        # East
+        if col < (n_cols-1):
+            new_gdq[integ, group:, row, col+1] |= CHLO_DNU
+
+        # West
+        if col > 0:
+            new_gdq[integ, group:, row, col-1] |= CHLO_DNU
 
     return new_gdq
diff --git a/jwst/exp_to_source/exp_to_source.py b/jwst/exp_to_source/exp_to_source.py
index c8765cd21..b9540b1b1 100644
--- a/jwst/exp_to_source/exp_to_source.py
+++ b/jwst/exp_to_source/exp_to_source.py
@@ -40,8 +40,26 @@ def exp_to_source(inputs):
             log.debug(f'Copying source {slit.source_id}')
             result_slit = result[str(slit.source_id)]
             result_slit.exposures.append(slit)
+            # store values for later use (after merge_tree)
+            # these values are incorrectly getting overwritten by
+            # the top model.
+            slit_bunit = slit.meta.bunit_data
+            slit_bunit_err = slit.meta.bunit_err
+            slit_model = slit.meta.model_type
+            slit_wcsinfo = slit.meta.wcsinfo.instance
+            # exposure.meta.bunit_data and bunit_err does not exist
+            # before calling merge_tree save these values
+            # Before merge_tree the slits have a model_type of SlitModel.
+            # After merge_tree it is overwritten with MultiSlitModel.
+            # store the model type to undo overwriting of modeltype.
+
             merge_tree(result_slit.exposures[-1].meta.instance, exposure.meta.instance)
 
+            result_slit.exposures[-1].meta.bunit_data = slit_bunit
+            result_slit.exposures[-1].meta.bunit_err = slit_bunit_err
+            result_slit.exposures[-1].meta.model_type = slit_model
+            result_slit.exposures[-1].meta.wcsinfo = slit_wcsinfo
+
             if result_slit.meta.instrument.name is None:
                 result_slit.update(exposure)
 
diff --git a/jwst/lib/basic_utils.py b/jwst/lib/basic_utils.py
index 28971ddb8..92e77dcf4 100644
--- a/jwst/lib/basic_utils.py
+++ b/jwst/lib/basic_utils.py
@@ -1,5 +1,31 @@
 """General utility objects"""
 
+from stdatamodels.jwst.datamodels import dqflags
+import numpy as np
+
+
+def set_nans_to_donotuse(data, dq):
+    """Set all NaN values in the data that have an even value to
+    DO_NOT_USE.
+
+    Parameters
+    ----------
+    data : numpy array
+        The science data array to find NaN values and
+        check of these have a DQ flag=DO_NOT_USE, or
+        set it if not.
+
+    dq : numpy array
+        The DQ array to be checked.
+
+    Returns
+    -------
+    dq : numpy array
+        The updated DQ array.
+    """
+    dq[np.isnan(data)] |= dqflags.pixel['DO_NOT_USE']
+    return dq
+
 
 class LoggingContext:
     """Logging context manager
diff --git a/jwst/pathloss/pathloss.py b/jwst/pathloss/pathloss.py
index c3339bd27..4ad2f551b 100644
--- a/jwst/pathloss/pathloss.py
+++ b/jwst/pathloss/pathloss.py
@@ -10,6 +10,8 @@ import stdatamodels.jwst.datamodels as datamodels
 
 from jwst.assign_wcs import nirspec, util
 from jwst.lib.wcs_utils import get_wavelengths
+from jwst.lib.basic_utils import set_nans_to_donotuse
+
 
 log = logging.getLogger(__name__)
 log.setLevel(logging.DEBUG)
@@ -545,6 +547,9 @@ def do_correction_mos(data, pathloss, inverse=False, source_type=None, correctio
         slit.pathloss_point = correction.pathloss_point
         slit.pathloss_uniform = correction.pathloss_uniform
 
+        # check the dq flags have the correct value
+        slit.dq = set_nans_to_donotuse(slit.data, slit.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -608,6 +613,9 @@ def do_correction_fixedslit(data, pathloss, inverse=False, source_type=None, cor
         slit.pathloss_point = correction.pathloss_point
         slit.pathloss_uniform = correction.pathloss_uniform
 
+        # check the dq flags have the correct value
+        slit.dq = set_nans_to_donotuse(slit.data, slit.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -661,6 +669,9 @@ def do_correction_ifu(data, pathloss, inverse=False, source_type=None, correctio
     # This might be useful to other steps
     data.wavelength = correction.wavelength
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set the step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -702,6 +713,9 @@ def do_correction_lrs(data, pathloss, user_slit_loc):
     # This might be useful to other steps
     data.wavelength = correction.wavelength
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set the step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -794,6 +808,9 @@ def do_correction_soss(data, pathloss):
         data.var_flat /= pathloss_2d**2
     data.pathloss_point = pathloss_2d
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
diff --git a/jwst/tweakreg/astrometric_utils.py b/jwst/tweakreg/astrometric_utils.py
index 0144fdbb7..a3034cb6c 100644
--- a/jwst/tweakreg/astrometric_utils.py
+++ b/jwst/tweakreg/astrometric_utils.py
@@ -96,8 +96,10 @@ def create_astrometric_catalog(input_models, catalog="GAIADR3", output="ref_cat.
         else Time(input_models[0].meta.observation.date).decimalyear
     )
     ref_dict = get_catalog(fiducial[0], fiducial[1], epoch=epoch, sr=radius, catalog=catalog)
+    if len(ref_dict) == 0:
+        return ref_dict
+    
     colnames = ('ra', 'dec', 'mag', 'objID', 'epoch')
-
     ref_table = ref_dict[colnames]
 
     # Add catalog name as meta data
