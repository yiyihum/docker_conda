diff --git a/CHANGES.rst b/CHANGES.rst
index 5cedc0faa..1abae4c32 100644
--- a/CHANGES.rst
+++ b/CHANGES.rst
@@ -16,6 +16,15 @@ background
 - Updated to allow multi-integration (rateints) background exposures to have
   a different value of NINTS than the science exposure. [#8326]
 
+charge_migration
+----------------
+
+- Updated the CHARGELOSS flagging.  In an integration ramp, the first group in
+  the SCI data is found that is above the CHARGELOSS threshold and not flagged
+  as DO_NOT_USE.  This group, and all subsequent groups, are then flagged as
+  CHARGELOSS and DO_NOT_USE.  The four nearest pixel neighbor are then flagged
+  in the same group. [#8336]
+
 cube_build
 ----------
 
@@ -51,6 +60,12 @@ emicorr
 - Set skip=True by default in the code, to be turned on later by a parameter
   reference file. [#8171]
 
+exp_to_source
+-------------
+
+- Fixed a bug for multislit data that bunit values, model_type and wcsinfo was
+  was being overwritten with the top multispec model values. [#8294]
+
 extract_1d
 ----------
 
@@ -88,6 +103,10 @@ general
 
 - Update minimum required stdatamodels version to include 1.10.0 [#8322]
 
+- Update minimum required gwcs version to include 0.21.0 [#8337]
+
+- Remove unused asdf-transform-schemas dependency [#8337]
+
 jump
 ----
 
@@ -100,6 +119,13 @@ lib
 - Updated ``set_velocity_aberration`` to use datamodels instead of `astropy.io.fits` for opening
   and manipulating input files. [#8285]
 
+lib
+---
+
+- Added new function set_nans_to_donotuse in ``lib.basic_utils`` to
+  check the science data array for NaN values and check if they have
+  a DQ flag of DO_NOT_USE, or set it if not. [#8292]
+
 outlier_detection
 -----------------
 
@@ -111,13 +137,11 @@ outlier_detection
   original input files to accidentally get deleted instead of just the intermediate
   files. [#8263]
 
-resample
+pathloss
 --------
-- Updated exposure time weighting to use the measurement time 
-  (TMEASURE) when available. [#8212]
 
-- Removed product exposure time (``TEXPTIME``) from all computations
-  in the resample step. [#8212]
+- Added a check to find all NaN values in the data with a corresponding
+  even value flag in the DQ array, and convert them to DO_NOT_USE. [#8292]
 
 photom
 ------
@@ -167,6 +191,12 @@ refpix
 resample
 --------
 
+- Updated exposure time weighting to use the measurement time 
+  (TMEASURE) when available. [#8212]
+
+- Removed product exposure time (``TEXPTIME``) from all computations
+  in the resample step. [#8212]
+
 - Use the same ``iscale`` value for resampling science data and variance arrays. [#8159]
 
 - Changed to use the high-level APE 14 API (``pixel_to_world_values`` and
@@ -206,6 +236,9 @@ tweakreg
 - Suppress warnings from ``photutils.background.Background2D`` regarding
   NaNs in the input data. [#8308]
 
+- Fixed a bug that caused failures instead of warnings when no GAIA sources
+  were found within the bounding box of the input image. [#8334]
+
 
 1.13.4 (2024-01-25)
 ===================
diff --git a/jwst/charge_migration/charge_migration.py b/jwst/charge_migration/charge_migration.py
index 30e1b9bc1..ccfcc3836 100644
--- a/jwst/charge_migration/charge_migration.py
+++ b/jwst/charge_migration/charge_migration.py
@@ -5,6 +5,7 @@ import numpy as np
 
 from stdatamodels.jwst.datamodels import dqflags
 
+
 log = logging.getLogger(__name__)
 log.setLevel(logging.DEBUG)
 
@@ -72,72 +73,29 @@ def flag_pixels(data, gdq, signal_threshold):
         updated group dq array
     """
     n_ints, n_grps, n_rows, n_cols = gdq.shape
-
-    new_gdq = gdq.copy()   # Updated gdq
-
-    # Flag all exceedances with CHARGELOSS and NO_NOT_USE
-    chargeloss_pix = (data > signal_threshold) & (gdq != DNU)
-    new_gdq[chargeloss_pix] = np.bitwise_or(new_gdq[chargeloss_pix], CHLO | DNU)
-
-    # Reset groups previously flagged as DNU
-    gdq_orig = gdq.copy()  # For resetting to previously flagged DNU
-    wh_gdq_DNU = np.bitwise_and(gdq_orig, DNU)
-
-    # Get indices for exceedances
-    arg_where = np.argwhere(new_gdq == CHLO_DNU)
-
-    a_int = arg_where[:, 0]  # array of integrations
-    a_grp = arg_where[:, 1]  # array of groups
-    a_row = arg_where[:, 2]  # array of rows
-    a_col = arg_where[:, 3]  # array of columns
-
-    # Process the 4 nearest neighbors of each exceedance
-    # Pixel to the east
-    xx_max_p1 = a_col[a_col < (n_cols-1)] + 1
-    i_int = a_int[a_col < (n_cols-1)]
-    i_grp = a_grp[a_col < (n_cols-1)]
-    i_row = a_row[a_col < (n_cols-1)]
-
-    if len(xx_max_p1) > 0:
-        new_gdq[i_int, i_grp, i_row, xx_max_p1] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, i_row, xx_max_p1], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the west
-    xx_m1 = a_col[a_col > 0] - 1
-    i_int = a_int[a_col > 0]
-    i_grp = a_grp[a_col > 0]
-    i_row = a_row[a_col > 0]
-
-    if len(xx_m1) > 0:
-        new_gdq[i_int, i_grp, i_row, xx_m1] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, i_row, xx_m1], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the north
-    yy_m1 = a_row[a_row > 0] - 1
-    i_int = a_int[a_row > 0]
-    i_grp = a_grp[a_row > 0]
-    i_col = a_col[a_row > 0]
-
-    if len(yy_m1) > 0:
-        new_gdq[i_int, i_grp, yy_m1, i_col] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, yy_m1, i_col], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
-
-    # Pixel to the south
-    yy_max_p1 = a_row[a_row < (n_rows-1)] + 1
-    i_int = a_int[a_row < (n_rows-1)]
-    i_grp = a_grp[a_row < (n_rows-1)]
-    i_col = a_col[a_row < (n_rows-1)]
-
-    if len(yy_max_p1) > 0:
-        new_gdq[i_int, i_grp, yy_max_p1, i_col] = \
-            np.bitwise_or(new_gdq[i_int, i_grp, yy_max_p1, i_col], CHLO | DNU)
-
-    new_gdq[wh_gdq_DNU == 1] = gdq_orig[wh_gdq_DNU == 1]  # reset for earlier DNUs
+    chargeloss_pix = np.where((data > signal_threshold) & (gdq != DNU))
+
+    new_gdq = gdq.copy()
+    
+    for k in range(len(chargeloss_pix[0])): 
+        integ, group = chargeloss_pix[0][k], chargeloss_pix[1][k]
+        row, col = chargeloss_pix[2][k], chargeloss_pix[3][k]
+        new_gdq[integ, group:, row, col] |= CHLO_DNU
+
+        # North
+        if row > 0:
+            new_gdq[integ, group:, row-1, col] |= CHLO_DNU
+
+        # South
+        if row < (n_rows-1):
+            new_gdq[integ, group:, row+1, col] |= CHLO_DNU
+
+        # East
+        if col < (n_cols-1):
+            new_gdq[integ, group:, row, col+1] |= CHLO_DNU
+
+        # West
+        if col > 0:
+            new_gdq[integ, group:, row, col-1] |= CHLO_DNU
 
     return new_gdq
diff --git a/jwst/exp_to_source/exp_to_source.py b/jwst/exp_to_source/exp_to_source.py
index c8765cd21..b9540b1b1 100644
--- a/jwst/exp_to_source/exp_to_source.py
+++ b/jwst/exp_to_source/exp_to_source.py
@@ -40,8 +40,26 @@ def exp_to_source(inputs):
             log.debug(f'Copying source {slit.source_id}')
             result_slit = result[str(slit.source_id)]
             result_slit.exposures.append(slit)
+            # store values for later use (after merge_tree)
+            # these values are incorrectly getting overwritten by
+            # the top model.
+            slit_bunit = slit.meta.bunit_data
+            slit_bunit_err = slit.meta.bunit_err
+            slit_model = slit.meta.model_type
+            slit_wcsinfo = slit.meta.wcsinfo.instance
+            # exposure.meta.bunit_data and bunit_err does not exist
+            # before calling merge_tree save these values
+            # Before merge_tree the slits have a model_type of SlitModel.
+            # After merge_tree it is overwritten with MultiSlitModel.
+            # store the model type to undo overwriting of modeltype.
+
             merge_tree(result_slit.exposures[-1].meta.instance, exposure.meta.instance)
 
+            result_slit.exposures[-1].meta.bunit_data = slit_bunit
+            result_slit.exposures[-1].meta.bunit_err = slit_bunit_err
+            result_slit.exposures[-1].meta.model_type = slit_model
+            result_slit.exposures[-1].meta.wcsinfo = slit_wcsinfo
+
             if result_slit.meta.instrument.name is None:
                 result_slit.update(exposure)
 
diff --git a/jwst/lib/basic_utils.py b/jwst/lib/basic_utils.py
index 28971ddb8..92e77dcf4 100644
--- a/jwst/lib/basic_utils.py
+++ b/jwst/lib/basic_utils.py
@@ -1,5 +1,31 @@
 """General utility objects"""
 
+from stdatamodels.jwst.datamodels import dqflags
+import numpy as np
+
+
+def set_nans_to_donotuse(data, dq):
+    """Set all NaN values in the data that have an even value to
+    DO_NOT_USE.
+
+    Parameters
+    ----------
+    data : numpy array
+        The science data array to find NaN values and
+        check of these have a DQ flag=DO_NOT_USE, or
+        set it if not.
+
+    dq : numpy array
+        The DQ array to be checked.
+
+    Returns
+    -------
+    dq : numpy array
+        The updated DQ array.
+    """
+    dq[np.isnan(data)] |= dqflags.pixel['DO_NOT_USE']
+    return dq
+
 
 class LoggingContext:
     """Logging context manager
diff --git a/jwst/pathloss/pathloss.py b/jwst/pathloss/pathloss.py
index c3339bd27..4ad2f551b 100644
--- a/jwst/pathloss/pathloss.py
+++ b/jwst/pathloss/pathloss.py
@@ -10,6 +10,8 @@ import stdatamodels.jwst.datamodels as datamodels
 
 from jwst.assign_wcs import nirspec, util
 from jwst.lib.wcs_utils import get_wavelengths
+from jwst.lib.basic_utils import set_nans_to_donotuse
+
 
 log = logging.getLogger(__name__)
 log.setLevel(logging.DEBUG)
@@ -545,6 +547,9 @@ def do_correction_mos(data, pathloss, inverse=False, source_type=None, correctio
         slit.pathloss_point = correction.pathloss_point
         slit.pathloss_uniform = correction.pathloss_uniform
 
+        # check the dq flags have the correct value
+        slit.dq = set_nans_to_donotuse(slit.data, slit.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -608,6 +613,9 @@ def do_correction_fixedslit(data, pathloss, inverse=False, source_type=None, cor
         slit.pathloss_point = correction.pathloss_point
         slit.pathloss_uniform = correction.pathloss_uniform
 
+        # check the dq flags have the correct value
+        slit.dq = set_nans_to_donotuse(slit.data, slit.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -661,6 +669,9 @@ def do_correction_ifu(data, pathloss, inverse=False, source_type=None, correctio
     # This might be useful to other steps
     data.wavelength = correction.wavelength
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set the step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -702,6 +713,9 @@ def do_correction_lrs(data, pathloss, user_slit_loc):
     # This might be useful to other steps
     data.wavelength = correction.wavelength
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set the step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
@@ -794,6 +808,9 @@ def do_correction_soss(data, pathloss):
         data.var_flat /= pathloss_2d**2
     data.pathloss_point = pathloss_2d
 
+    # check the dq flags have the correct value
+    data.dq = set_nans_to_donotuse(data.data, data.dq)
+
     # Set step status to complete
     data.meta.cal_step.pathloss = 'COMPLETE'
 
diff --git a/jwst/tweakreg/astrometric_utils.py b/jwst/tweakreg/astrometric_utils.py
index 0144fdbb7..a3034cb6c 100644
--- a/jwst/tweakreg/astrometric_utils.py
+++ b/jwst/tweakreg/astrometric_utils.py
@@ -96,8 +96,10 @@ def create_astrometric_catalog(input_models, catalog="GAIADR3", output="ref_cat.
         else Time(input_models[0].meta.observation.date).decimalyear
     )
     ref_dict = get_catalog(fiducial[0], fiducial[1], epoch=epoch, sr=radius, catalog=catalog)
+    if len(ref_dict) == 0:
+        return ref_dict
+    
     colnames = ('ra', 'dec', 'mag', 'objID', 'epoch')
-
     ref_table = ref_dict[colnames]
 
     # Add catalog name as meta data
diff --git a/pyproject.toml b/pyproject.toml
index 20dbc5433..0bbbdfa71 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -20,12 +20,11 @@ classifiers = [
 ]
 dependencies = [
     "asdf>=2.15.1,<4",
-    "asdf-transform-schemas>=0.3.0",
     "astropy>=5.3",
     "BayesicFitting>=3.0.1",
     "crds>=11.17.14",
     "drizzle>=1.14.3,<1.15.0",
-    "gwcs>=0.20.0,<0.21.0",
+    "gwcs>=0.21.0,<0.22.0",
     "numpy>=1.22",
     "opencv-python-headless>=4.6.0.66",
     "photutils>=1.5.0",
