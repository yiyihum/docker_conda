diff --git a/AUTHORS b/AUTHORS
index 4617b7d..934bbe3 100644
--- a/AUTHORS
+++ b/AUTHORS
@@ -31,9 +31,11 @@ Alphabetical list of contributors:
 * Florian Bauer <florian.bauer@zmdi.com>
 * Fredy Wijaya <fredy.wijaya@gmail.com>
 * Gavin Wahl <gwahl@fusionbox.com>
+* Georg Traar <georg@crate.io>
 * Hugo van Kemenade <hugovk@users.noreply.github.com>
 * hurcy <cinyoung.hur@gmail.com>
 * Ian Robertson <ian.robertson@capitalone.com>
+* Igor Khrol <igor.khrol@automattic.com>
 * JacekPliszka <Jacek.Pliszka@gmail.com>
 * JavierPan <PeterSandwich@users.noreply.github.com>
 * Jean-Martin Archer <jm@jmartin.ca>
diff --git a/CHANGELOG b/CHANGELOG
index 0ede280..cbfbcf2 100644
--- a/CHANGELOG
+++ b/CHANGELOG
@@ -10,10 +10,12 @@ Enhancements:
 
 * Splitting statements now allows to remove the semicolon at the end.
   Some database backends love statements without semicolon (issue742).
+* Support TypedLiterals in get_parameters (pr649, by Khrol).
 
 Bug Fixes
 
 * Ignore dunder attributes when creating Tokens (issue672).
+* Allow operators to precede dollar-quoted strings (issue763).
 
 
 Release 0.4.4 (Apr 18, 2023)
diff --git a/docs/source/extending.rst b/docs/source/extending.rst
index 0c10924..866303b 100644
--- a/docs/source/extending.rst
+++ b/docs/source/extending.rst
@@ -70,7 +70,7 @@ a keyword to the lexer:
     lex.add_keywords(keywords.KEYWORDS)
 
     # add a custom keyword dictionary
-    lex.add_keywords({'BAR', sqlparse.tokens.Keyword})
+    lex.add_keywords({'BAR': sqlparse.tokens.Keyword})
 
     # no configuration is passed here. The lexer is used as a singleton.
     sqlparse.parse("select * from foo zorder by bar;")
diff --git a/sqlparse/engine/grouping.py b/sqlparse/engine/grouping.py
index 57d257e..c486318 100644
--- a/sqlparse/engine/grouping.py
+++ b/sqlparse/engine/grouping.py
@@ -360,6 +360,7 @@ def group_functions(tlist):
         tidx, token = tlist.token_next_by(t=T.Name, idx=tidx)
 
 
+@recurse(sql.Identifier)
 def group_order(tlist):
     """Group together Identifier and Asc/Desc token"""
     tidx, token = tlist.token_next_by(t=T.Keyword.Order)
diff --git a/sqlparse/keywords.py b/sqlparse/keywords.py
index b45f3e0..d3794fd 100644
--- a/sqlparse/keywords.py
+++ b/sqlparse/keywords.py
@@ -30,7 +30,7 @@ SQL_REGEX = [
 
     (r"`(``|[^`])*`", tokens.Name),
     (r"´(´´|[^´])*´", tokens.Name),
-    (r'((?<!\S)\$(?:[_A-ZÀ-Ü]\w*)?\$)[\s\S]*?\1', tokens.Literal),
+    (r'((?<![\w\"\$])\$(?:[_A-ZÀ-Ü]\w*)?\$)[\s\S]*?\1', tokens.Literal),
 
     (r'\?', tokens.Name.Placeholder),
     (r'%(\(\w+\))?s', tokens.Name.Placeholder),
diff --git a/sqlparse/sql.py b/sqlparse/sql.py
index 1ccfbdb..41606dd 100644
--- a/sqlparse/sql.py
+++ b/sqlparse/sql.py
@@ -619,12 +619,14 @@ class Function(NameAliasMixin, TokenList):
     def get_parameters(self):
         """Return a list of parameters."""
         parenthesis = self.tokens[-1]
+        result = []
         for token in parenthesis.tokens:
             if isinstance(token, IdentifierList):
                 return token.get_identifiers()
-            elif imt(token, i=(Function, Identifier), t=T.Literal):
-                return [token, ]
-        return []
+            elif imt(token, i=(Function, Identifier, TypedLiteral),
+                     t=T.Literal):
+                result.append(token)
+        return result
 
 
 class Begin(TokenList):
