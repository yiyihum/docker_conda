diff --git a/sktime/forecasting/model_selection/tests/test_tune.py b/sktime/forecasting/model_selection/tests/test_tune.py
index 12afc70a7..f374e51a6 100644
--- a/sktime/forecasting/model_selection/tests/test_tune.py
+++ b/sktime/forecasting/model_selection/tests/test_tune.py
@@ -1,9 +1,8 @@
 #!/usr/bin/env python3 -u
 # copyright: sktime developers, BSD-3-Clause License (see LICENSE file)
-"""Test grid search CV."""
+"""Test forecasting tuners."""
 
 __author__ = ["mloning", "fkiraly"]
-__all__ = ["test_gscv", "test_rscv"]
 
 import numpy as np
 import pytest
@@ -81,12 +80,13 @@ def _check_cv(forecaster, tuner, cv, param_grid, y, X, scoring):
     assert param_grid[best_idx].items() <= fitted_params.items()
 
 
-def _create_hierarchical_data():
+def _create_hierarchical_data(n_columns=1):
     y = _make_hierarchical(
         random_state=TEST_RANDOM_SEEDS[0],
         hierarchy_levels=(2, 2),
         min_timepoints=15,
         max_timepoints=15,
+        n_columns=n_columns,
     )
     X = _make_hierarchical(
         random_state=TEST_RANDOM_SEEDS[1],
@@ -97,7 +97,10 @@ def _create_hierarchical_data():
     return y, X
 
 
-NAIVE = NaiveForecaster(strategy="mean")
+# estimator fixtures used for tuning
+# set_tags in NaiveForecaster ensures that it is univariate and broadcasts
+# this is currently the case, but a future improved NaiveForecaster may reduce coverage
+NAIVE = NaiveForecaster(strategy="mean").set_tags(**{"scitype:y": "univariate"})
 NAIVE_GRID = {"window_length": TEST_WINDOW_LENGTHS_INT}
 PIPE = TransformedTargetForecaster(
     [
@@ -126,15 +129,24 @@ ERROR_SCORES = [np.nan, "raise", 1000]
 @pytest.mark.parametrize("scoring", TEST_METRICS)
 @pytest.mark.parametrize("cv", CVs)
 @pytest.mark.parametrize("error_score", ERROR_SCORES)
-def test_gscv(forecaster, param_grid, cv, scoring, error_score):
+@pytest.mark.parametrize("multivariate", [True, False])
+def test_gscv(forecaster, param_grid, cv, scoring, error_score, multivariate):
     """Test ForecastingGridSearchCV."""
-    y, X = load_longley()
+    if multivariate:
+        X, y = load_longley()
+    else:
+        y, X = load_longley()
+
     gscv = ForecastingGridSearchCV(
         forecaster,
         param_grid=param_grid,
         cv=cv,
         scoring=scoring,
         error_score=error_score,
+        # todo 0.24.0: remove this
+        # and/or add a test for tune_by_variable=True
+        # in this case, the forecaster is expeceted to vectorize over columns
+        tune_by_variable=False,
     )
     gscv.fit(y, X)
 
@@ -177,6 +189,7 @@ def test_rscv(forecaster, param_grid, cv, scoring, error_score, n_iter, random_s
         ParameterSampler(param_grid, n_iter, random_state=random_state)
     )
     _check_cv(forecaster, rscv, cv, param_distributions, y, X, scoring)
+    _check_fitted_params_keys(rscv.get_fitted_params())
 
 
 @pytest.mark.skipif(
@@ -189,20 +202,26 @@ def test_rscv(forecaster, param_grid, cv, scoring, error_score, n_iter, random_s
 @pytest.mark.parametrize("scoring", TEST_METRICS)
 @pytest.mark.parametrize("cv", CVs)
 @pytest.mark.parametrize("error_score", ERROR_SCORES)
-def test_gscv_hierarchical(forecaster, param_grid, cv, scoring, error_score):
+@pytest.mark.parametrize("n_cols", [1, 2])
+def test_gscv_hierarchical(forecaster, param_grid, cv, scoring, error_score, n_cols):
     """Test ForecastingGridSearchCV."""
-    y, X = _create_hierarchical_data()
+    y, X = _create_hierarchical_data(n_columns=n_cols)
     gscv = ForecastingGridSearchCV(
         forecaster,
         param_grid=param_grid,
         cv=cv,
         scoring=scoring,
         error_score=error_score,
+        # todo 0.24.0: remove this
+        # and/or add a test for tune_by_variable=True
+        # in this case, the forecaster is expeceted to vectorize over columns
+        tune_by_variable=False,
     )
     gscv.fit(y, X)
 
     param_grid = ParameterGrid(param_grid)
     _check_cv(forecaster, gscv, cv, param_grid, y, X, scoring)
+    _check_fitted_params_keys(gscv.get_fitted_params())
 
 
 @pytest.mark.skipif(
diff --git a/sktime/proba/tests/test_all_distrs.py b/sktime/proba/tests/test_all_distrs.py
index 5e8594495..5808d9d2c 100644
--- a/sktime/proba/tests/test_all_distrs.py
+++ b/sktime/proba/tests/test_all_distrs.py
@@ -72,7 +72,7 @@ class TestAllDistributions(DistributionFixtureGenerator, QuickTester):
         assert (res_panel.index == dummy_panel.index).all()
         assert (res_panel.columns == dummy_panel.columns).all()
 
-    @pytest.mark.parametrize("method", METHODS_SCALAR)
+    @pytest.mark.parametrize("method", METHODS_SCALAR, ids=METHODS_SCALAR)
     def test_methods_scalar(self, estimator_instance, method):
         """Test expected return of scalar methods."""
         if not _has_capability(estimator_instance, method):
@@ -83,7 +83,7 @@ class TestAllDistributions(DistributionFixtureGenerator, QuickTester):
 
         _check_output_format(res, d, method)
 
-    @pytest.mark.parametrize("method", METHODS_X)
+    @pytest.mark.parametrize("method", METHODS_X, ids=METHODS_X)
     def test_methods_x(self, estimator_instance, method):
         """Test expected return of methods that take sample-like argument."""
         if not _has_capability(estimator_instance, method):
@@ -95,7 +95,7 @@ class TestAllDistributions(DistributionFixtureGenerator, QuickTester):
 
         _check_output_format(res, d, method)
 
-    @pytest.mark.parametrize("method", METHODS_P)
+    @pytest.mark.parametrize("method", METHODS_P, ids=METHODS_P)
     def test_methods_p(self, estimator_instance, method):
         """Test expected return of methods that take percentage-like argument."""
         if not _has_capability(estimator_instance, method):
diff --git a/sktime/registry/tests/test_tags.py b/sktime/registry/tests/test_tags.py
new file mode 100644
index 000000000..e3e738163
--- /dev/null
+++ b/sktime/registry/tests/test_tags.py
@@ -0,0 +1,24 @@
+"""Tests for tag register an tag functionality."""
+
+from sktime.registry._tags import ESTIMATOR_TAG_REGISTER
+
+
+def test_tag_register_type():
+    """Test the specification of the tag register. See _tags for specs."""
+    assert isinstance(ESTIMATOR_TAG_REGISTER, list)
+    assert all(isinstance(tag, tuple) for tag in ESTIMATOR_TAG_REGISTER)
+
+    for tag in ESTIMATOR_TAG_REGISTER:
+        assert len(tag) == 4
+        assert isinstance(tag[0], str)
+        assert isinstance(tag[1], (str, list))
+        if isinstance(tag[1], list):
+            assert all(isinstance(x, str) for x in tag[1])
+        assert isinstance(tag[2], (str, tuple))
+        if isinstance(tag[2], tuple):
+            assert len(tag[2]) == 2
+            assert isinstance(tag[2][0], str)
+            assert isinstance(tag[2][1], (list, str))
+            if isinstance(tag[2][1], list):
+                assert all(isinstance(x, str) for x in tag[2][1])
+        assert isinstance(tag[3], str)
