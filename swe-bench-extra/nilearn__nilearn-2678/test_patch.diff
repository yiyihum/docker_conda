diff --git a/nilearn/datasets/tests/test_neurovault.py b/nilearn/datasets/tests/test_neurovault.py
index 74cccbbe3..53c907a8e 100644
--- a/nilearn/datasets/tests/test_neurovault.py
+++ b/nilearn/datasets/tests/test_neurovault.py
@@ -431,7 +431,7 @@ def test_result_filter():
     filter_0 = neurovault.ResultFilter(query_terms={'a': 0},
                                        callable_filter=lambda d: len(d) < 5,
                                        b=1)
-    assert np.unicode(filter_0) == u'ResultFilter'
+    assert str(filter_0) == 'ResultFilter'
     assert filter_0['a'] == 0
     assert filter_0({'a': 0, 'b': 1, 'c': 2})
     assert not filter_0({'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4})
diff --git a/nilearn/decomposition/tests/test_canica.py b/nilearn/decomposition/tests/test_canica.py
index ce2b58fa6..07c5e59a2 100644
--- a/nilearn/decomposition/tests/test_canica.py
+++ b/nilearn/decomposition/tests/test_canica.py
@@ -158,8 +158,13 @@ def test_percentile_range():
     canica = CanICA(n_components=edge_case, threshold=float(edge_case))
     with warnings.catch_warnings(record=True) as warning:
         canica.fit(data)
-        assert len(warning) == 1  # ensure single warning
-        assert "critical threshold" in str(warning[-1].message)
+        # Filter out deprecation warnings
+        not_deprecation_warning = [not issubclass(w.category,
+                                                  DeprecationWarning)
+                                        for w in warning]
+        assert sum(not_deprecation_warning) == 1  # ensure single warning
+        idx_critical_warning = not_deprecation_warning.index(True)
+        assert "critical threshold" in str(warning[idx_critical_warning].message)
 
 
 def test_masker_attributes_with_fit():
diff --git a/nilearn/input_data/tests/test_nifti_maps_masker.py b/nilearn/input_data/tests/test_nifti_maps_masker.py
index 34dd02765..cb142c9f8 100644
--- a/nilearn/input_data/tests/test_nifti_maps_masker.py
+++ b/nilearn/input_data/tests/test_nifti_maps_masker.py
@@ -132,7 +132,8 @@ def test_nifti_maps_masker_with_nans():
 
     # nans
     maps_data = get_data(maps_img)
-    mask_data = get_data(mask_img)
+    mask_data = np.array(get_data(mask_img),
+                         dtype=np.float64)
 
     maps_data[:, 9, 9] = np.nan
     maps_data[:, 5, 5] = np.inf
diff --git a/nilearn/surface/tests/test_surface.py b/nilearn/surface/tests/test_surface.py
index 1c5879bc2..8d0c15d7f 100644
--- a/nilearn/surface/tests/test_surface.py
+++ b/nilearn/surface/tests/test_surface.py
@@ -4,6 +4,7 @@ import os
 import tempfile
 import warnings
 
+from collections import namedtuple
 from distutils.version import LooseVersion
 
 import nibabel as nb
@@ -20,7 +21,7 @@ from nilearn import datasets
 from nilearn import image
 from nilearn.image import resampling
 from nilearn.image.tests.test_resampling import rotation
-from nilearn.surface import Mesh
+from nilearn.surface import Mesh, Surface
 from nilearn.surface import surface
 from nilearn.surface import load_surf_data, load_surf_mesh, vol_to_surf
 from nilearn.surface.surface import (_gifti_img_to_mesh,
@@ -47,6 +48,23 @@ class MeshLikeObject(object):
     def faces(self):
         return self._faces
 
+class SurfaceLikeObject(object):
+    """Class with attributes mesh and
+    data to be used for testing purposes.
+    """
+    def __init__(self, mesh, data):
+        self._mesh = mesh
+        self._data = data
+    @classmethod
+    def fromarrays(cls, coordinates, faces, data):
+        return cls(MeshLikeObject(coordinates, faces), data)
+    @property
+    def mesh(self):
+        return self._mesh
+    @property
+    def data(self):
+        return self._data
+
 
 def test_load_surf_data_array():
     # test loading and squeezing data from numpy array
@@ -182,6 +200,39 @@ def test_load_surf_mesh():
     assert_array_equal(mesh_like.faces, loaded_mesh.faces)
 
 
+def test_load_surface():
+    coords, faces = generate_surf()
+    mesh = Mesh(coords, faces)
+    data = mesh[0][:,0]
+    surf = Surface(mesh, data)
+    surf_like_obj = SurfaceLikeObject(mesh, data)
+    # Load the surface from:
+    #   - Surface-like objects having the right attributes
+    #   - a list of length 2 (mesh, data)
+    for loadings in [surf,
+                     surf_like_obj,
+                     [mesh, data]]:
+        s = surface.load_surface(loadings)
+        assert_array_equal(s.data, data)
+        assert_array_equal(s.data, surf.data)
+        assert_array_equal(s.mesh.coordinates, coords)
+        assert_array_equal(s.mesh.coordinates, surf.mesh.coordinates)
+        assert_array_equal(s.mesh.faces, surf.mesh.faces)
+    # Giving an iterable of length other than 2 will raise an error
+    # Length 3
+    with pytest.raises(ValueError,
+                       match="`load_surface` accepts iterables of length 2"):
+        s = surface.load_surface([coords, faces, data])
+    # Length 1
+    with pytest.raises(ValueError,
+                       match="`load_surface` accepts iterables of length 2"):
+        s = surface.load_surface([coords])
+    # Giving other objects will raise an error
+    with pytest.raises(ValueError,
+                       match="Wrong parameter `surface` in `load_surface`"):
+        s = surface.load_surface("foo")
+
+
 def test_load_surf_mesh_list():
     # test if correct list is returned
     mesh = generate_surf()
@@ -661,9 +712,41 @@ def test_check_mesh_and_data():
     wrong_faces = rng.randint(coords.shape[0] + 1, size=(30, 3))
     wrong_mesh = Mesh(coords, wrong_faces)
     # Check that check_mesh_and_data raises an error with the resulting wrong mesh
-    with pytest.raises(ValueError, match="Mismatch between the indices of faces and the number of nodes."):
+    with pytest.raises(ValueError,
+                       match="Mismatch between the indices of faces and the number of nodes."):
         surface.check_mesh_and_data(wrong_mesh, data)
     # Alter the data and check that an error is raised
     data = mesh[0][::2, 0]
-    with pytest.raises(ValueError, match="Mismatch between number of nodes in mesh"):
+    with pytest.raises(ValueError,
+                       match="Mismatch between number of nodes in mesh"):
         surface.check_mesh_and_data(mesh, data)
+
+
+def test_check_surface():
+    coords, faces = generate_surf()
+    mesh = Mesh(coords, faces)
+    data = mesh[0][:,0]
+    surf = Surface(mesh, data)
+    s = surface.check_surface(surf)
+    assert_array_equal(s.data, data)
+    assert_array_equal(s.data, surf.data)
+    assert_array_equal(s.mesh.coordinates, coords)
+    assert_array_equal(s.mesh.coordinates, mesh.coordinates)
+    assert_array_equal(s.mesh.faces, faces)
+    assert_array_equal(s.mesh.faces, mesh.faces)
+    # Generate faces such that max index is larger than
+    # the length of coordinates array.
+    rng = np.random.RandomState(42)
+    wrong_faces = rng.randint(coords.shape[0] + 1, size=(30, 3))
+    wrong_mesh = Mesh(coords, wrong_faces)
+    wrong_surface = Surface(wrong_mesh, data)
+    # Check that check_mesh_and_data raises an error with the resulting wrong mesh
+    with pytest.raises(ValueError,
+                       match="Mismatch between the indices of faces and the number of nodes."):
+        surface.check_surface(wrong_surface)
+    # Alter the data and check that an error is raised
+    wrong_data = mesh[0][::2, 0]
+    wrong_surface = Surface(mesh, wrong_data)
+    with pytest.raises(ValueError,
+                       match="Mismatch between number of nodes in mesh"):
+        surface.check_surface(wrong_surface)
