diff --git a/pytorch_memlab/line_profiler/line_profiler.py b/pytorch_memlab/line_profiler/line_profiler.py
index 04c1fa2..7615ef1 100644
--- a/pytorch_memlab/line_profiler/line_profiler.py
+++ b/pytorch_memlab/line_profiler/line_profiler.py
@@ -6,7 +6,7 @@ import torch
 from .line_records import LineRecords
 
 # Seaborn's `muted` color cycle
-DEFAULT_COLUMNS = ['active_bytes.all.peak', 'reserved_bytes.all.peak']
+DEFAULT_COLUMNS = ('active_bytes.all.peak', 'reserved_bytes.all.peak')
 
 
 class LineProfiler:
@@ -88,8 +88,9 @@ class LineProfiler:
         try:
             torch.cuda.empty_cache()
             self._reset_cuda_stats()
-        except AssertionError as e:
-            print('Could not reset CUDA stats and cache: ' + str(e))
+        # Pytorch-1.7.0 raises AttributeError while <1.6.0 raises AssertionError
+        except (AssertionError, AttributeError) as error:
+            print('Could not reset CUDA stats and cache: ' + str(error))
 
         self.register_callback()
 
diff --git a/pytorch_memlab/mem_reporter.py b/pytorch_memlab/mem_reporter.py
index 6aff270..c2f3800 100644
--- a/pytorch_memlab/mem_reporter.py
+++ b/pytorch_memlab/mem_reporter.py
@@ -27,13 +27,15 @@ class MemReporter():
         self.device_tensor_stat = {}
         # to numbering the unknown tensors
         self.name_idx = 0
+
+        tensor_names = defaultdict(list)
         if model is not None:
             assert isinstance(model, torch.nn.Module)
             # for model with tying weight, multiple parameters may share
             # the same underlying tensor
-            tensor_names = defaultdict(list)
             for name, param in model.named_parameters():
                 tensor_names[param].append(name)
+
         for param, name in tensor_names.items():
             self.tensor_name[id(param)] = '+'.join(name)
 

