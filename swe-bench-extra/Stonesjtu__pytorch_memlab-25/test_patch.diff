diff --git a/test/test_mem_reporter.py b/test/test_mem_reporter.py
index 971e8f1..927d7fe 100644
--- a/test/test_mem_reporter.py
+++ b/test/test_mem_reporter.py
@@ -7,8 +7,8 @@ import pytest
 concentrate_mode = False
 
 def test_reporter():
-    linear = torch.nn.Linear(1024, 1024).cuda()
-    inp = torch.Tensor(512, 1024).cuda()
+    linear = torch.nn.Linear(1024, 1024)
+    inp = torch.Tensor(512, 1024)
     reporter = MemReporter(linear)
 
     out = linear(inp*(inp+3)).mean()
@@ -17,16 +17,27 @@ def test_reporter():
 
     reporter.report()
 
+def test_reporter_without_model():
+    linear = torch.nn.Linear(1024, 1024)
+    inp = torch.Tensor(512, 1024)
+    reporter = MemReporter()
+
+    out = linear(inp*(inp+3)).mean()
+    reporter.report()
+    out.backward()
+
+    reporter.report()
+
 @pytest.mark.skipif(concentrate_mode, reason='concentrate')
 def test_reporter_tie_weight():
-    linear = torch.nn.Linear(1024, 1024).cuda()
-    linear_2 = torch.nn.Linear(1024, 1024).cuda()
+    linear = torch.nn.Linear(1024, 1024)
+    linear_2 = torch.nn.Linear(1024, 1024)
     linear_2.weight = linear.weight
     container = torch.nn.Sequential(
         linear, linear_2
     )
     reporter = MemReporter(container)
-    inp = torch.Tensor(512, 1024).cuda()
+    inp = torch.Tensor(512, 1024)
 
     out = container(inp).mean()
     out.backward()
@@ -34,6 +45,7 @@ def test_reporter_tie_weight():
     reporter = MemReporter(container)
     reporter.report()
 
+@pytest.mark.skipif(not torch.cuda.is_available(), reason='no CUDA')
 @pytest.mark.skipif(concentrate_mode, reason='concentrate')
 def test_reporter_LSTM():
     lstm = torch.nn.LSTM(256, 256, num_layers=1).cuda()
@@ -45,6 +57,7 @@ def test_reporter_LSTM():
     reporter = MemReporter(lstm)
     reporter.report()
 
+@pytest.mark.skipif(not torch.cuda.is_available(), reason='no CUDA')
 @pytest.mark.skipif(concentrate_mode, reason='concentrate')
 def test_reporter_device():
     lstm_cpu = torch.nn.LSTM(256, 256)
