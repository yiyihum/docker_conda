diff --git a/tests/test_tokens.py b/tests/test_tokens.py
index 30af34fe..d5a2b7f5 100644
--- a/tests/test_tokens.py
+++ b/tests/test_tokens.py
@@ -1,5 +1,6 @@
 import unittest
 
+from sqlglot.dialects import BigQuery
 from sqlglot.tokens import Tokenizer, TokenType
 
 
@@ -68,7 +69,8 @@ x"""
             Tokenizer().tokenize("select /*")
 
     def test_jinja(self):
-        tokenizer = Tokenizer()
+        # Check that {#, #} are treated as token delimiters, even though BigQuery overrides COMMENTS
+        tokenizer = BigQuery.Tokenizer()
 
         tokens = tokenizer.tokenize(
             """
diff --git a/tests/test_transpile.py b/tests/test_transpile.py
index 1085b092..8d762d33 100644
--- a/tests/test_transpile.py
+++ b/tests/test_transpile.py
@@ -280,6 +280,11 @@ FROM v""",
             "select * from t where ((condition = 1)/*test*/)",
             "SELECT * FROM t WHERE ((condition = 1) /* test */)",
         )
+        self.validate(
+            "SELECT 1 // hi this is a comment",
+            "SELECT 1 /* hi this is a comment */",
+            read="snowflake",
+        )
 
     def test_types(self):
         self.validate("INT 1", "CAST(1 AS INT)")
