diff --git a/fitbenchmarking/utils/tests/test_options.py b/fitbenchmarking/utils/tests/test_options.py
index da5e66a3..acc98f5f 100644
--- a/fitbenchmarking/utils/tests/test_options.py
+++ b/fitbenchmarking/utils/tests/test_options.py
@@ -42,6 +42,7 @@ class OptionsTests(unittest.TestCase):
             file_name: THE_LOG.log
             append: yes
             level: debug
+            external_output: no
             """
         incorrect_config_str = """
             [FITTING]
@@ -51,6 +52,7 @@ class OptionsTests(unittest.TestCase):
             make_plots: incorrect_falue
             [LOGGING]
             append: sure
+            external_output: maybe
             """
         opts = {'MINIMIZERS': {'scipy': ['nonesense',
                                          'another_fake_minimizer'],
@@ -67,7 +69,8 @@ class OptionsTests(unittest.TestCase):
                              'results_dir': 'new_results'},
                 'LOGGING': {'file_name': 'THE_LOG.log',
                             'append': True,
-                            'level': 'debug'}}
+                            'level': 'debug',
+                            'external_output': False}}
 
         opts_file = 'test_options_tests_{}.txt'.format(
             datetime.datetime.now())
@@ -163,6 +166,18 @@ class OptionsTests(unittest.TestCase):
         logging_opts = self.options['LOGGING']
         self.assertEqual(logging_opts['append'], options.log_append)
 
+    def test_log_external_output_false(self):
+        with self.assertRaises(exceptions.OptionsError) as cm:
+            Options(file_name=self.options_file_incorrect)
+        excep = cm.exception
+        self.assertIn('external_output', excep._obj_message)
+
+    def test_log_external_output_true(self):
+        options = Options(file_name=self.options_file)
+        logging_opts = self.options['LOGGING']
+        self.assertEqual(logging_opts['external_output'],
+                         options.external_output)
+
 
 if __name__ == '__main__':
     unittest.main()
diff --git a/fitbenchmarking/utils/tests/test_output_grabber.py b/fitbenchmarking/utils/tests/test_output_grabber.py
index 45bb404f..a9700f40 100644
--- a/fitbenchmarking/utils/tests/test_output_grabber.py
+++ b/fitbenchmarking/utils/tests/test_output_grabber.py
@@ -2,13 +2,16 @@ from __future__ import (absolute_import, division, print_function)
 import unittest
 
 from fitbenchmarking.utils.output_grabber import OutputGrabber
-
+from fitbenchmarking.utils.options import Options
 
 class OutputGrabberTests(unittest.TestCase):
 
+    def setUp(self):
+        self.options = Options()
+
     def test_correct_output(self):
         output_string = 'This is the correct output string\nSecond line'
-        output = OutputGrabber()
+        output = OutputGrabber(self.options)
         with output:
             print(output_string)
         # print adds an extra \n
@@ -16,12 +19,11 @@ class OutputGrabberTests(unittest.TestCase):
 
     def test_incorrect_output(self):
         output_string = 'This is the correct output string\nSecond line'
-        incorrect_output_sting = 'This is the incorrect string'
-        output = OutputGrabber()
+        incorrect_output_sting = 'This is the incorrect string\n'
+        output = OutputGrabber(self.options)
         with output:
             print(output_string)
-        # print adds an extra \n
-        assert output.capturedtext != incorrect_output_sting + "\n"
+        assert output.capturedtext != incorrect_output_sting
 
 
 if __name__ == "__main__":
