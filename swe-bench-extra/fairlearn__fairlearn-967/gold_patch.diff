diff --git a/docs/user_guide/installation_and_version_guide/v0.7.1.rst b/docs/user_guide/installation_and_version_guide/v0.7.1.rst
index 39f145d..bf7a992 100644
--- a/docs/user_guide/installation_and_version_guide/v0.7.1.rst
+++ b/docs/user_guide/installation_and_version_guide/v0.7.1.rst
@@ -15,3 +15,5 @@ v0.7.1
 * Fixed a bug whereby passing a custom :code:`grid` object to a :code:`GridSearch`
   reduction would result in a :code:`KeyError` if the column names were not ordered
   integers.
+* :class:`~fairlearn.preprocessing.CorrelationRemover` now exposes
+  :code:`n_features_in_` and :code:`feature_names_in_`.
\ No newline at end of file
diff --git a/fairlearn/metrics/_extra_metrics.py b/fairlearn/metrics/_extra_metrics.py
index 474116e..e970f28 100644
--- a/fairlearn/metrics/_extra_metrics.py
+++ b/fairlearn/metrics/_extra_metrics.py
@@ -61,7 +61,7 @@ def _get_labels_for_confusion_matrix(labels, pos_label):
     # Ensure unique_labels has two elements
     if len(unique_labels) == 1:
         if unique_labels[0] == pos_label:
-            unique_labels = [None, pos_label]
+            unique_labels = [np.iinfo(np.int64).min, pos_label]
         else:
             unique_labels.append(pos_label)
     elif len(unique_labels) == 2:
diff --git a/fairlearn/preprocessing/_correlation_remover.py b/fairlearn/preprocessing/_correlation_remover.py
index ceebe78..955f6bc 100644
--- a/fairlearn/preprocessing/_correlation_remover.py
+++ b/fairlearn/preprocessing/_correlation_remover.py
@@ -71,13 +71,16 @@ class CorrelationRemover(BaseEstimator, TransformerMixin):
         if isinstance(X, pd.DataFrame):
             self.lookup_ = {c: i for i, c in enumerate(X.columns)}
             return X.values
+        # correctly handle a 1d input
+        if len(X.shape) == 1:
+            return {0: 0}
         self.lookup_ = {i: i for i in range(X.shape[1])}
         return X
 
     def fit(self, X, y=None):
         """Learn the projection required to make the dataset uncorrelated with sensitive columns."""  # noqa: E501
         self._create_lookup(X)
-        X = check_array(X, estimator=self)
+        X = self._validate_data(X)
         X_use, X_sensitive = self._split_X(X)
         self.sensitive_mean_ = X_sensitive.mean()
         X_s_center = X_sensitive - self.sensitive_mean_
@@ -88,7 +91,9 @@ class CorrelationRemover(BaseEstimator, TransformerMixin):
     def transform(self, X):
         """Transform X by applying the correlation remover."""
         X = check_array(X, estimator=self)
-        check_is_fitted(self, ["beta_", "X_shape_", "lookup_", "sensitive_mean_"])
+        check_is_fitted(
+            self, ["beta_", "X_shape_", "lookup_", "sensitive_mean_"]
+        )
         if self.X_shape_[1] != X.shape[1]:
             raise ValueError(
                 f"The trained data has {self.X_shape_[1]} features while this dataset has "
@@ -100,3 +105,17 @@ class CorrelationRemover(BaseEstimator, TransformerMixin):
         X_use = np.atleast_2d(X_use)
         X_filtered = np.atleast_2d(X_filtered)
         return self.alpha * X_filtered + (1 - self.alpha) * X_use
+
+    def _more_tags(self):
+        return {
+            "_xfail_checks": {
+                "check_parameters_default_constructible": (
+                    "sensitive_feature_ids has to be explicitly set to "
+                    "instantiate this estimator"
+                ),
+                "check_transformer_data_not_an_array": (
+                    "this estimator only accepts pandas dataframes or numpy "
+                    "ndarray as input."
+                )
+            }
+        }
