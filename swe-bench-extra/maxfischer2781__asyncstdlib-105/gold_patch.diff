diff --git a/.codecov.yml b/.codecov.yml
new file mode 100644
index 0000000..d19a3b7
--- /dev/null
+++ b/.codecov.yml
@@ -0,0 +1,3 @@
+ignore:
+  # type tests are not execute, so there is no code coverage
+  - "typetests"
diff --git a/asyncstdlib/_lrucache.pyi b/asyncstdlib/_lrucache.pyi
new file mode 100644
index 0000000..38794cc
--- /dev/null
+++ b/asyncstdlib/_lrucache.pyi
@@ -0,0 +1,61 @@
+from ._typing import AC, Protocol, R as R, TypedDict
+from typing import (
+    Any,
+    Awaitable,
+    Callable,
+    NamedTuple,
+    Optional,
+    overload,
+)
+
+class CacheInfo(NamedTuple):
+    hits: int
+    misses: int
+    maxsize: Optional[int]
+    currsize: int
+
+class CacheParameters(TypedDict):
+    maxsize: Optional[int]
+    typed: bool
+
+class LRUAsyncCallable(Protocol[AC]):
+    __call__: AC
+    @overload
+    def __get__(
+        self: LRUAsyncCallable[AC],
+        instance: None,
+        owner: Optional[type] = ...,
+    ) -> LRUAsyncCallable[AC]: ...
+    @overload
+    def __get__(
+        self: LRUAsyncCallable[Callable[..., Awaitable[R]]],
+        instance: object,
+        owner: Optional[type] = ...,
+    ) -> LRUAsyncBoundCallable[Callable[..., Awaitable[R]]]: ...
+    @property
+    def __wrapped__(self) -> AC: ...
+    def cache_parameters(self) -> CacheParameters: ...
+    def cache_info(self) -> CacheInfo: ...
+    def cache_clear(self) -> None: ...
+    def cache_discard(self, *args: Any, **kwargs: Any) -> None: ...
+
+class LRUAsyncBoundCallable(LRUAsyncCallable[AC]):
+    __self__: object
+    __call__: AC
+    def __get__(
+        self: LRUAsyncBoundCallable[AC],
+        instance: Any,
+        owner: Optional[type] = ...,
+    ) -> LRUAsyncBoundCallable[AC]: ...
+    def __init__(self, lru: LRUAsyncCallable[AC], __self__: object) -> None: ...
+    @property
+    def __wrapped__(self) -> AC: ...
+    @property
+    def __func__(self) -> LRUAsyncCallable[AC]: ...
+
+@overload
+def lru_cache(maxsize: AC, typed: bool = ...) -> LRUAsyncCallable[AC]: ...
+@overload
+def lru_cache(
+    maxsize: Optional[int] = ..., typed: bool = ...
+) -> Callable[[AC], LRUAsyncCallable[AC]]: ...
diff --git a/asyncstdlib/itertools.py b/asyncstdlib/itertools.py
index fc12573..f6f06ee 100644
--- a/asyncstdlib/itertools.py
+++ b/asyncstdlib/itertools.py
@@ -148,33 +148,54 @@ class chain(AsyncIterator[T]):
     The resulting iterator consecutively iterates over and yields all values from
     each of the ``iterables``. This is similar to converting all ``iterables`` to
     sequences and concatenating them, but lazily exhausts each iterable.
+
+    The ``chain`` assumes ownership of its ``iterables`` and closes them reliably
+    when the ``chain`` is closed. Pass the ``iterables`` via a :py:class:`tuple` to
+    ``chain.from_iterable`` to avoid closing all iterables but those already processed.
     """
 
-    __slots__ = ("_impl",)
+    __slots__ = ("_iterator", "_owned_iterators")
 
-    def __init__(self, *iterables: AnyIterable[T]):
-        async def impl() -> AsyncIterator[T]:
-            for iterable in iterables:
+    @staticmethod
+    async def _chain_iterator(
+        any_iterables: AnyIterable[AnyIterable[T]],
+    ) -> AsyncGenerator[T, None]:
+        async with ScopedIter(any_iterables) as iterables:
+            async for iterable in iterables:
                 async with ScopedIter(iterable) as iterator:
                     async for item in iterator:
                         yield item
 
-        self._impl = impl()
+    def __init__(
+        self, *iterables: AnyIterable[T], _iterables: AnyIterable[AnyIterable[T]] = ()
+    ):
+        self._iterator = self._chain_iterator(iterables or _iterables)
+        self._owned_iterators = (
+            iterable
+            for iterable in iterables
+            if isinstance(iterable, AsyncIterator) and hasattr(iterable, "aclose")
+        )
 
-    @staticmethod
-    async def from_iterable(iterable: AnyIterable[AnyIterable[T]]) -> AsyncIterator[T]:
+    @classmethod
+    def from_iterable(cls, iterable: AnyIterable[AnyIterable[T]]) -> "chain[T]":
         """
         Alternate constructor for :py:func:`~.chain` that lazily exhausts
-        iterables as well
+        the ``iterable`` of iterables as well
+
+        This is suitable for chaining iterables from a lazy or infinite ``iterable``.
+        In turn, closing the ``chain`` only closes those iterables
+        already fetched from ``iterable``.
         """
-        async with ScopedIter(iterable) as iterables:
-            async for sub_iterable in iterables:
-                async with ScopedIter(sub_iterable) as iterator:
-                    async for item in iterator:
-                        yield item
+        return cls(_iterables=iterable)
 
     def __anext__(self) -> Awaitable[T]:
-        return self._impl.__anext__()
+        return self._iterator.__anext__()
+
+    async def aclose(self) -> None:
+        for iterable in self._owned_iterators:
+            if hasattr(iterable, "aclose"):
+                await iterable.aclose()
+        await self._iterator.aclose()
 
 
 async def compress(
diff --git a/pyproject.toml b/pyproject.toml
index 1b46000..92cb0aa 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -43,8 +43,11 @@ doc = ["sphinx", "sphinxcontrib-trio"]
 Documentation = "https://asyncstdlib.readthedocs.io/en/latest/"
 Source = "https://github.com/maxfischer2781/asyncstdlib"
 
+[tool.flit.sdist]
+include = ["unittests"]
+
 [tool.mypy]
-files = ["asyncstdlib/*.py"]
+files = ["asyncstdlib", "typetests"]
 check_untyped_defs = true
 no_implicit_optional = true
 warn_redundant_casts = true
@@ -59,3 +62,8 @@ disallow_untyped_decorators = true
 warn_return_any = true
 no_implicit_reexport = true
 strict_equality = true
+
+[tool.pytest.ini_options]
+testpaths = [
+    "unittests",
+]
