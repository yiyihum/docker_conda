diff --git a/tests/test_lattice.py b/tests/test_lattice.py
index cf4b890..14d6a66 100644
--- a/tests/test_lattice.py
+++ b/tests/test_lattice.py
@@ -33,7 +33,7 @@ class TestLattice(unittest.TestCase):
         lattice = Lattice(5, SYS_DIC)
         self.assertEqual(7, len(lattice.snodes))
         self.assertTrue(isinstance(lattice.snodes[0][0], BOS))
-        self.assertEqual(9, len(lattice.enodes))
+        self.assertEqual(8, len(lattice.enodes))
         self.assertTrue(isinstance(lattice.enodes[1][0], BOS))
 
     def test_add_forward_end(self):
diff --git a/tests/test_tokenizer.py b/tests/test_tokenizer.py
index cc249d2..1928cf5 100644
--- a/tests/test_tokenizer.py
+++ b/tests/test_tokenizer.py
@@ -173,6 +173,13 @@ class TestTokenizer(unittest.TestCase):
                 text = unicode(text)
             tokens = Tokenizer().tokenize(text)
 
+    def test_tokenize_large_text3(self):
+        with open('tests/text_large_nonjp.txt', encoding='utf-8') as f:
+            text = f.read()
+            if not PY3:
+                text = unicode(text)
+            tokens = Tokenizer().tokenize(text)
+
     def test_tokenize_large_text_stream(self):
         with open('tests/text_lemon.txt', encoding='utf-8') as f:
             text = f.read()
@@ -187,6 +194,13 @@ class TestTokenizer(unittest.TestCase):
                 text = unicode(text)
             tokens = list(Tokenizer().tokenize(text, stream = True))
 
+    def test_tokenize_large_text_stream3(self):
+        with open('tests/text_large_nonjp.txt', encoding='utf-8') as f:
+            text = f.read()
+            if not PY3:
+                text = unicode(text)
+            tokens = list(Tokenizer().tokenize(text, stream = True))
+
     def test_tokenize_wakati(self):
         text = u'すもももももももものうち'
         tokens = Tokenizer(wakati = True).tokenize(text, wakati = True)
diff --git a/tests/text_large_nonjp.txt b/tests/text_large_nonjp.txt
new file mode 100644
index 0000000..fa61527
--- /dev/null
+++ b/tests/text_large_nonjp.txt
@@ -0,0 +1,1 @@
+longlonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglonglongtext
