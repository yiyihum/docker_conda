diff --git a/tests/test_loky_module.py b/tests/test_loky_module.py
index 474f49d..b9734ea 100644
--- a/tests/test_loky_module.py
+++ b/tests/test_loky_module.py
@@ -10,7 +10,7 @@ import pytest
 
 import loky
 from loky import cpu_count
-from loky.backend.context import _cpu_count_user
+from loky.backend.context import _cpu_count_user, _MAX_WINDOWS_WORKERS
 
 
 def test_version():
@@ -34,6 +34,11 @@ def test_cpu_count():
     assert 1 <= cpus_physical <= cpus
 
 
+@pytest.mark.skipif(sys.platform != "win32", reason="Windows specific test")
+def test_windows_max_cpu_count():
+    assert cpu_count() <= _MAX_WINDOWS_WORKERS
+
+
 cpu_count_cmd = (
     "from loky.backend.context import cpu_count;" "print(cpu_count({args}))"
 )
diff --git a/tests/test_reusable_executor.py b/tests/test_reusable_executor.py
index f45e7ed..f9b99d4 100644
--- a/tests/test_reusable_executor.py
+++ b/tests/test_reusable_executor.py
@@ -20,6 +20,7 @@ from loky import get_reusable_executor
 from loky.process_executor import _RemoteTraceback, TerminatedWorkerError
 from loky.process_executor import BrokenProcessPool, ShutdownExecutorError
 from loky.reusable_executor import _ReusablePoolExecutor
+from loky.backend.context import _MAX_WINDOWS_WORKERS
 
 try:
     import psutil
@@ -220,7 +221,6 @@ class CExitAtGCInWorker:
 
 
 class TestExecutorDeadLock(ReusableExecutorMixin):
-
     crash_cases = [
         # Check problem occuring while pickling a task in
         (id, (ExitAtPickle(),), PicklingError, None),
@@ -1013,3 +1013,41 @@ class TestExecutorInitializer(ReusableExecutorMixin):
         out, err = p.communicate()
         assert p.returncode == 1, out.decode()
         assert b"resource_tracker" not in err, err.decode()
+
+
+def test_no_crash_max_workers_on_windows():
+    # Check that loky's reusable process pool executor does not crash when the
+    # user asks for more workers than the maximum number of workers supported
+    # by the platform.
+
+    # Note: on overloaded CI hosts, spawning many processes can take a long
+    # time. We need to increase the timeout to avoid spurious failures when
+    # making assertions on `len(executor._processes)`.
+    idle_worker_timeout = 10 * 60
+    with warnings.catch_warnings(record=True) as record:
+        executor = get_reusable_executor(
+            max_workers=_MAX_WINDOWS_WORKERS + 1, timeout=idle_worker_timeout
+        )
+        assert executor.submit(lambda: None).result() is None
+    if sys.platform == "win32":
+        assert len(record) == 1
+        assert "max_workers" in str(record[0].message)
+        assert len(executor._processes) == _MAX_WINDOWS_WORKERS
+    else:
+        assert len(record) == 0
+        assert len(executor._processes) == _MAX_WINDOWS_WORKERS + 1
+
+    # Downsizing should never raise a warning.
+    before_downsizing_executor = executor
+    with warnings.catch_warnings(record=True) as record:
+        executor = get_reusable_executor(
+            max_workers=_MAX_WINDOWS_WORKERS, timeout=idle_worker_timeout
+        )
+        assert executor.submit(lambda: None).result() is None
+
+    # No warning on any OS when max_workers does not exceed the limit.
+    assert len(record) == 0
+    assert before_downsizing_executor is executor
+    assert len(executor._processes) == _MAX_WINDOWS_WORKERS
+
+    executor.shutdown()
